{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statSuma_v1.3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FHjdh1JtlPq"
      },
      "source": [
        "ðŸŠ **statSuma *v*.1.3.** ðŸŠ\n",
        "---\n",
        "\n",
        "\n",
        "**Citation:**\n",
        "\n",
        "Leigh R.J., Murphy R.A., and Walsh F. (2021) Paper title, Journal metrics\n",
        "\n",
        "\n",
        "**Description:**\n",
        "\n",
        "statSuma is a user-friendly script for deciding (and performing) the most appropriate statistical tests in microbiome studies \n",
        "\n",
        "\n",
        "**Please read the manual**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-nhKh-2bEff",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to upload a dataset file**\n",
        "import io\n",
        "import itertools\n",
        "import matplotlib\n",
        "import matplotlib.backends.backend_pdf\n",
        "import matplotlib.patches as mpatches \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from scipy.stats import norm\n",
        "from sklearn import preprocessing\n",
        "from statsmodels.sandbox.stats.multicomp import multipletests\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "dataset = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlaMOT9OGp3-",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to set critical alpha values**\n",
        "#@markdown This step sets the critical alpha values to determine if data is equivariant and Gaussian. This is set to **0.05** by default but can be changed to any float between 0 and 1 by clicking on this cell.\n",
        "\n",
        "pairwise_equivariance_critical_alpha = 0.05\n",
        "pairwise_gaussian_critical_alpha = 0.05\n",
        "listwise_gaussian_critical_alpha = 0.05\n",
        "listwise_equivariance_critical_alpha = 0.05\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihZMN4qvS1f",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to scale (normalise) data**\n",
        "#@markdown Data scaling results in the cumulative reads for each sample equating to the same value. The default is **\"yes\"** but this can be changed by clicking on this box. \n",
        "\n",
        "scale_data = \"yes\"\n",
        "\n",
        "def Scale(item):\n",
        "    scaler = item.astype(float).sum(axis=0)/item.astype(float).sum(axis=0).max()\n",
        "    scaledData = item.astype(float)/scaler\n",
        "    scaledInputData = scaledData.values.tolist()\n",
        "    return scaledData, scaledInputData\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJBPJF-EbRP-",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to conduct pairwise tests**\n",
        "\n",
        "#@markdown ðŸŠ **The recommended pairwise test is printed below this cell when completed** ðŸŠ\n",
        "\n",
        "#@markdown This step computes a two-tailed Brunner-Munzel test, Mann-Whitney U-test, Welch's t-test, and Student's t-test and a two-sample Kruskal-Wallis H-test for each taxon between each pair of sites. A Bonferroni-Dunn correction (PBD) is also computed for each returned P-value. This step uses a Shapiro-Wilk test to determine data normality (whether the data was sampled from a Gaussian distribution) and a Levene's test to determine equivariance between each sample set. Gaussian likelihood and equivariance likelihood results are used to determine which pairwise test is most appropriate.\n",
        "\n",
        "datasetName = next(iter(dataset))\n",
        "dataset_df = pd.read_csv(io.BytesIO(dataset[datasetName]), sep='\\t', header=None).set_index(0)\n",
        "dataset_head = pd.DataFrame(dataset_df.iloc[0].tolist())\n",
        "dataset_head = dataset_head.rename(columns={0:\"Group\"}).T #.set_index('Group')\n",
        "\n",
        "if scale_data==\"yes\":\n",
        "  sdata1, sdata2 = Scale(dataset_df.drop('Group'))\n",
        "  sdata1 = sdata1.T.reset_index().T.drop('index')\n",
        "  dataset_df = pd.concat([dataset_head, sdata1])\n",
        "  #dataset_df1 = dataset_head.append(sdata1)\n",
        "else:\n",
        "  dataset_df = dataset_df\n",
        "\n",
        "\n",
        "\n",
        "groupedData = dataset_df.T.groupby(\"Group\", axis=0)\n",
        "groups = set(dataset_df.iloc[0].tolist())\n",
        "taxa = list(dataset_df.T.columns)[1:]\n",
        "\n",
        "reformatted_data = []\n",
        "\n",
        "for group in groups:\n",
        "  rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "  for taxonID, dataSeries in rawDataset.iteritems():\n",
        "    dataSeries = list(dataSeries.astype(np.float))\n",
        "    x = [taxonID, group, list(dataSeries)]\n",
        "    reformatted_data.append(x)\n",
        "\n",
        "results = []\n",
        "BrunnerMunzelResults = []\n",
        "StudentResults = []\n",
        "WelchResults = []\n",
        "MannWhitneyResults = []\n",
        "KruskalResults = []\n",
        "\n",
        "combi = itertools.combinations(reformatted_data,2)\n",
        "for groupA, groupB in combi:\n",
        "  if (groupA[0]==groupB[0]) and (groupA[1]!=groupB[1]):\n",
        "    lenA, lenB = len(groupA[2]), len(groupB[2])\n",
        "    if (np.mean(groupA[2]) > 0) and (np.std(groupA[2])>0) and (np.mean(groupB[2])>0) and (np.std(groupB[2])>0) and (lenA > 1) and (lenB > 1):\n",
        "      L, P = stats.levene(groupA[2], groupB[2])\n",
        "      K1, KP1 = stats.shapiro(groupA[2])\n",
        "      K2, KP2 = stats.shapiro(groupB[2])\n",
        "      Mean1, SD1, Median1, Var1, min1, max1 = np.mean(groupA[2]), np.std(groupA[2]), np.median(groupA[2]), np.var(groupA[2]), min(groupA[2]), max(groupA[2])\n",
        "      Mean2, SD2, Median2, Var2, min2, max2 = np.mean(groupB[2]), np.std(groupB[2]), np.median(groupB[2]), np.var(groupB[2]), min(groupB[2]), max(groupB[2])\n",
        "      Brunner_Stat, Brunner_P = stats.brunnermunzel(groupA[2], groupB[2])\n",
        "      Student_Stat, Student_P = stats.ttest_ind(groupA[2], groupB[2], equal_var=True)\n",
        "      Welch_Stat, Welch_P = stats.ttest_ind(groupA[2], groupB[2], equal_var=False)\n",
        "      KW_Stat, KW_P = stats.kruskal(groupA[2], groupB[2])\n",
        "      MW_Stat, MW_P = stats.mannwhitneyu(groupA[2], groupB[2])\n",
        "      if Mean1 > Mean2:\n",
        "        MeanDifference = \"Decrease\"\n",
        "      elif Mean1 < Mean2:\n",
        "        MeanDifference = \"Increase\"\n",
        "      else:\n",
        "        MeanDifference = \"NoChange\"    \n",
        "      if Median1 > Median2:\n",
        "        MedianDifference = \"Decrease\"\n",
        "      elif Median1 < Median2:\n",
        "        MedianDifference = \"Increase\"\n",
        "      else:\n",
        "        MedianDifference = \"NoChange\"\n",
        "      if P >= pairwise_equivariance_critical_alpha:\n",
        "        equivariance = \"equivariant\"\n",
        "      else:\n",
        "        equivariance = \"non-equivariant\"\n",
        "      if KP1 >= pairwise_gaussian_critical_alpha:\n",
        "        distribution1 = \"gaussian\"\n",
        "      else:\n",
        "        distribution1 = \"non-gaussian\"\n",
        "      if KP2 >= pairwise_gaussian_critical_alpha:\n",
        "        distribution2 = \"gaussian\"\n",
        "      else:\n",
        "       distribution2 = \"non-gaussian\"\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, Brunner_Stat, Brunner_P]\n",
        "      BrunnerMunzelResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, MW_Stat, MW_P]\n",
        "      MannWhitneyResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, KW_Stat, KW_P]\n",
        "      KruskalResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MeanDifference, Student_Stat, Student_P]\n",
        "      StudentResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MeanDifference, Welch_Stat, Welch_P]\n",
        "      WelchResults.append(ComparisonResult)\n",
        "      if (distribution1 == \"gaussian\") and (distribution2 == \"gaussian\") and (equivariance == \"equivariant\"):\n",
        "        recommendation = \"Students_t_test\"\n",
        "      elif (distribution1 == \"gaussian\") and (distribution2 == \"gaussian\") and (equivariance == \"non-equivariant\"):\n",
        "        recommendation = \"Welchs_t_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"non-equivariant\") and min(lenA,lenB)>9:\n",
        "        recommendation = \"Brunner-Munzel_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"non-equivariant\") and min(lenA,lenB)<9 and min(lenA,lenB)>4:\n",
        "        recommendation = \"Kruskal-Wallis_H_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"equivariant\") and min(lenA,lenB)>7:\n",
        "       recommendation = \"Mann-Whitney_U_test\"\n",
        "      elif min(lenA,lenB)<4 and (equivariance == \"equivariant\"):\n",
        "        recommendation = \"Size_Students_t_test\"\n",
        "      elif min(lenA,lenB)<4 and (equivariance == \"non-equivariant\"):\n",
        "        recommendation = \"Size_Welchs_t_test\"\n",
        "      else:\n",
        "        \"Check_statistics\"\n",
        "      result = [groupA[0], groupA[1], groupB[1], lenA, lenB, L, K1, K2, P, KP1, KP2, equivariance, distribution1, distribution2, recommendation]\n",
        "      results.append(result)\n",
        "\n",
        "tests_df = pd.DataFrame.from_records(results, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"SizeA\", \"SizeB\", \"Levenes_Stat\", \"KS_StatA\", \"KS_StatB\", \"Levenes_Pvalue\", \"KS_PvalueA\", \"KS_PvalueB\", \"Equivariant?\", \"GroupA_Gaussian?\", \"GroupB_Gaussian?\", \"Recommended_test\"])\n",
        "BrunnerMunzelResults_df = pd.DataFrame.from_records(BrunnerMunzelResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "StudentResults_df = pd.DataFrame.from_records(StudentResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "WelchResults_df = pd.DataFrame.from_records(WelchResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "MannWhitneyResults_df = pd.DataFrame.from_records(MannWhitneyResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "KruskalResults_df = pd.DataFrame.from_records(KruskalResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "\n",
        "res_df = tests_df['Recommended_test'].value_counts()\n",
        "set_tests = tests_df['Recommended_test'].unique()\n",
        "if \"Kruskal-Wallis_H_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Kruskal-Wallis H test\\n***\\n\")\n",
        "elif \"Brunner-Munzel_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Brunner-Munzel test\\n***\\n\") \n",
        "elif \"Welchs_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Welchs t test\\n***\\n\") \n",
        "elif \"Students_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Students t test\\n***\\n\") \n",
        "elif \"Mann-Whitney_U_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Mann-Whitney U test\\n***\\n\")\n",
        "elif \"Size_Welchs_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Size-based Welchs t test\\n***\\n\") \n",
        "elif \"Size_Students_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Size-based Students t test\\n***\\n\") \n",
        "\n",
        "if \"Size_\" in set_tests:\n",
        "  print(\"\\n***Warning: A \\\"size based\\\" t-test was invoked for one or more comparisons.\\nThis happens when the sample size is below 5 in a given group.\\nPlease check your data\")\n",
        "\n",
        "KruskalResults_df['PBD'] = multipletests(KruskalResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "BrunnerMunzelResults_df['PBD'] = multipletests(BrunnerMunzelResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "StudentResults_df['PBD'] = multipletests(StudentResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "WelchResults_df['PBD'] = multipletests(WelchResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "MannWhitneyResults_df['PBD'] = multipletests(MannWhitneyResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "\n",
        "tests_df.to_csv(\"RecommendedPairwiseComparisons.tsv\", sep='\\t', header=True, index=False)\n",
        "KruskalResults_df.to_csv(\"KruskalPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "BrunnerMunzelResults_df.to_csv(\"BrunnerMunzelPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "StudentResults_df.to_csv(\"StudentPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "WelchResults_df.to_csv(\"WelchPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "MannWhitneyResults_df.to_csv(\"MannWhitneyPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "recTable = pd.DataFrame(tests_df['Recommended_test'].value_counts()).rename(columns={\"Recommended_test\":\"n\"})\n",
        "recTable['%'] = round((recTable/recTable.sum()*100),3)\n",
        "print(\"\\n***\\nThe below table shows the number of tests (n) associated with each test\\nand their associated percentage of the total number of tests (%)\\n***\")\n",
        "recTable\n",
        "\n",
        "#dataset_df\n",
        "#sdata1.T.reset_index().T.drop('index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhhM6e4ux5PD",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to conduct listwise tests**\n",
        "\n",
        "#@markdown ðŸŠ **The recommended listwise test is printed below this cell when completed** ðŸŠ\n",
        "\n",
        "#@markdown This step computes an ANOVA and a Kruskal-Wallis H-test for each taxon between each pair of sites. A Bonferroni-Dunn correction (PBD) is also computed for each returned P-value. This step uses a Shapiro-Wilk test to determine data normality (whether the data was sampled from a Gaussian distribution) and a Levene's test to determine equivariance between each sample set. Gaussian likelihood and equivariance likelihood results are used to determine which listwise test is most appropriate.\n",
        "\n",
        "\n",
        "ANOVA_results = []\n",
        "H_results = []\n",
        "listwise_results = []\n",
        "\n",
        "for taxon in taxa:\n",
        "  experimental = []\n",
        "  for group in reformatted_data:\n",
        "    if taxon == group[0]:\n",
        "      experimental.append(group[2])\n",
        "  groupings = [item for item in experimental]\n",
        "  Levenes_Stat, Levenes_P = stats.levene(*groupings)\n",
        "  KWS, KWP = stats.kruskal(*groupings)\n",
        "  ANS, ANP = stats.f_oneway(*groupings)\n",
        "  H_res = [taxon, KWS, KWP]\n",
        "  ANOVA_res = [taxon, ANS, ANP]\n",
        "  ANOVA_results.append(ANOVA_res)\n",
        "  H_results.append(H_res)\n",
        "  Gauss = []\n",
        "  for group in groupings:\n",
        "    KS, KP = stats.kstest(group, 'norm')\n",
        "    KSP = [KS, KP]\n",
        "    Gauss.append(KSP)\n",
        "  KS, KP = min(Gauss)\n",
        "  if (KP >= listwise_gaussian_critical_alpha) and (Levenes_P >= listwise_equivariance_critical_alpha):\n",
        "    recommendation = \"ANOVA\"\n",
        "  else:\n",
        "    recommendation = \"Kruskal-Wallis_H-test\"\n",
        "  lres = [taxon, Levenes_Stat, KS, Levenes_P, KP, recommendation]\n",
        "  listwise_results.append(lres)\n",
        "\n",
        "KruskalListwiseResults_df = pd.DataFrame.from_records(H_results, columns=[\"Taxon\", \"Statistic\", \"Pvalue\"])\n",
        "KruskalListwiseResults_df['PBD'] = multipletests(KruskalListwiseResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "KruskalListwiseResults_df.to_csv(\"KruskalListwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "ANOVAListwiseResults_df = pd.DataFrame.from_records(ANOVA_results, columns=[\"Taxon\", \"Statistic\", \"Pvalue\"])\n",
        "ANOVAListwiseResults_df['PBD'] = multipletests(ANOVAListwiseResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "ANOVAListwiseResults_df.to_csv(\"ANOVAListwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "tests_df = pd.DataFrame.from_records(listwise_results, columns=[\"Taxon\", \"Levene_Stat\", \"Levene_P\", \"min_KS_Stat\", \"min_KS_P\", \"Recommended_test\"])\n",
        "tests_df.to_csv(\"RecommendedListwiseComparisons.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "set_tests = tests_df['Recommended_test'].unique()\n",
        "if \"Kruskal-Wallis_H-test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Kruskal-Wallis H test\\n***\\n\")\n",
        "else:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is ANOVA\\n***\\n\") \n",
        "\n",
        "recTable = pd.DataFrame(tests_df['Recommended_test'].value_counts()).rename(columns={\"Recommended_test\":\"n\"})\n",
        "recTable['%'] = round((recTable/recTable.sum()*100),3)\n",
        "print(\"\\n***\\nThe below table shows the number of tests (n) associated with each test\\nand their associated percentage of the total number of tests (%)\\n***\")\n",
        "recTable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrqY_aKMalCK",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to plot variance distributions**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate differential variances. This step can be slow due to the volume of graphs produced (and data processed) for large and complex datasets. To speed up this process, only comparisons where the median of both datasets is greater than 0 are plotted.\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "combi = itertools.combinations(reformatted_data,2)\n",
        "with PdfPages(\"VarianceDistributions.pdf\") as pdf:\n",
        "  for groupA, groupB in combi:\n",
        "    if (groupA[0]==groupB[0]) and (groupA[1]!=groupB[1]):\n",
        "      if (np.mean(groupA[2]) > 0) and (np.std(groupA[2])>0) and (np.mean(groupB[2])>0) and (np.std(groupB[2])>0) and (np.median(groupA[2])>0) and (np.median(groupB[2])>0):\n",
        "        L, P = stats.levene(groupA[2], groupB[2])\n",
        "        groupAA = scaler.fit_transform(np.array(groupA[2]).reshape(-1,1)).tolist()\n",
        "        groupBB = scaler.fit_transform(np.array(groupB[2]).reshape(-1,1)).tolist()\n",
        "        groupAA = list(itertools.chain(*groupAA))\n",
        "        groupBB = list(itertools.chain(*groupBB))\n",
        "        z = pd.DataFrame([groupAA, groupBB]).T\n",
        "        ax = sns.displot(data=z, stat='probability', common_norm=False, kde='True', palette=['blue','red'], legend=None)\n",
        "        plt.title(groupA[0])\n",
        "        plt.xlabel('Standardised reads')\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_equivariance_critical_alpha :\n",
        "          ax2.set_ylabel(\"Equivariant (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_equivariance_critical_alpha) and (P > 0.001):\n",
        "          ax2.set_ylabel(\"Non-equivariant (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-equivariant (P = \"+format(P,'.3e')+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=groupA[1]),mpatches.Patch(facecolor='blue', label=groupB[1])]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()\n",
        "        del groupAA, groupBB\n",
        "        continue\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h91yZqPZuE8",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to plot data standardised distributions against a Gaussian distribution**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate whether a given taxon at a given site was sampled from a Gaussian distribution.\n",
        "\n",
        "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "with PdfPages(\"GaussianDistributions.pdf\") as pdf:  \n",
        "  for group in groups:\n",
        "    rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "    for taxonID, dataSeries in rawDataset.iteritems():\n",
        "      dataSeries = list(dataSeries.astype(np.float))\n",
        "      if (np.mean(dataSeries) > 0) and (np.std(dataSeries)>0) and (np.median(dataSeries)>0):\n",
        "        K,P = stats.shapiro(dataSeries)\n",
        "        dataSeries = scaler.fit_transform(np.array(dataSeries).reshape(-1,1)).tolist()\n",
        "        dataSeries = list(itertools.chain(*dataSeries))\n",
        "        normal_data = np.random.normal(loc=0.0, scale=1.0, size=min(len(dataSeries)**2, 10000))\n",
        "        z = pd.DataFrame([normal_data, dataSeries]).T\n",
        "        ax = sns.displot(data=z, stat='probability', common_norm=False, kde='True', palette=['blue','red'], legend=None)\n",
        "        plt.title(taxonID+\" (\"+group+\")\")\n",
        "        plt.xlabel('Standardised reads (deviations from the mean)')\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_gaussian_critical_alpha:\n",
        "          ax2.set_ylabel(\"Gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_gaussian_critical_alpha) and (P > 0.001):\n",
        "         ax2.set_ylabel(\"Non-gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+format(P,'.3e')+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=taxonID),mpatches.Patch(facecolor='blue', label=\"Gaussian distribution\")]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.25), ncol=2)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDAN_m_fbi9p",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to plot QQ-plots**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate whether a given taxon at a given site was sampled from a Gaussian distribution (presented in a linear QQ-plot format).\n",
        "\n",
        "\n",
        "with PdfPages(\"QQ_plots.pdf\") as pdf:  \n",
        "  for group in groups:\n",
        "    rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "    for taxonID, dataSeries in rawDataset.iteritems():\n",
        "      if (np.mean(dataSeries) > 0) and (np.std(dataSeries)>0) and (np.median(dataSeries)>0):        \n",
        "        dataSeries = np.array(dataSeries.astype(np.float))\n",
        "        K,P = stats.shapiro(dataSeries)\n",
        "        sm.qqplot(dataSeries, stats.norm, fit=True, line='45', loc=np.mean(dataSeries), scale=np.std(dataSeries))\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_gaussian_critical_alpha:\n",
        "          ax2.set_ylabel(\"Gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_gaussian_critical_alpha) and (P > 0.001):\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+format(P,'.3e')+\")\")\n",
        "        plt.title(taxonID+\" (\"+group+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=\"QQ-line (45 degrees)\"),mpatches.Patch(facecolor='blue', label=taxonID)]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.35), ncol=2)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74CwdeJKu-ys"
      },
      "source": [
        "**Accessing output files**\n",
        "\n",
        "Once all desired cells have been successfully ran, output files are accessed by clicking on the **folder** icon at the left of the screen. Below is a static image of the **folder** icon. \n",
        "\n",
        "![Screenshot 2021-06-10 at 17.24.12.png](data:image/png;base64,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)"
      ]
    }
  ]
}