{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statSuma_v1.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FHjdh1JtlPq"
      },
      "source": [
        "**statSuma *v*.1.2**\n",
        "---\n",
        "\n",
        "\n",
        "**Citation:**\n",
        "\n",
        "Leigh R.J., and Walsh F. (2021) Paper title, Journal metrics\n",
        "\n",
        "\n",
        "**Description:**\n",
        "\n",
        "statSuma is a user-friendly script for deciding (and performing) the most appropriate statistical tests in microbiome studies \n",
        "\n",
        "\n",
        "**Please read the manual**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-nhKh-2bEff",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "cellView": "form",
        "outputId": "cd0a8647-809a-48d8-ac74-e63aa9833764"
      },
      "source": [
        "#@title **Click here to upload a dataset file**\n",
        "import io\n",
        "import itertools\n",
        "import matplotlib\n",
        "import matplotlib.backends.backend_pdf\n",
        "import matplotlib.patches as mpatches \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from scipy.stats import norm\n",
        "from sklearn import preprocessing\n",
        "from statsmodels.sandbox.stats.multicomp import multipletests\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "dataset = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7d0a407-694b-45d7-a755-ce3556effa60\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7d0a407-694b-45d7-a755-ce3556effa60\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving human16S_exampleMicrobiome.tsv to human16S_exampleMicrobiome (4).tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlaMOT9OGp3-",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to set critical alpha values**\n",
        "#@markdown This step sets the critical alpha values to determine if data is equivariant and Gaussian. This is set to **0.05** by default but can be changed to any float between 0 and 1 by clicking on this cell.\n",
        "\n",
        "pairwise_equivariance_critical_alpha = 0.05\n",
        "pairwise_gaussian_critical_alpha = 0.05\n",
        "listwise_gaussian_critical_alpha = 0.05\n",
        "listwise_equivariance_critical_alpha = 0.05\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihZMN4qvS1f",
        "cellView": "form"
      },
      "source": [
        "#@title **Click here to scale (normalise) data**\n",
        "#@markdown Data scaling results in the cumulative reads for each sample equating to the same value. The default is **\"yes\"** but this can be changed by clicking on this box. \n",
        "\n",
        "scale_data = \"yes\"\n",
        "\n",
        "def Scale(item):\n",
        "    scaler = item.astype(float).sum(axis=0)/item.astype(float).sum(axis=0).max()\n",
        "    scaledData = item.astype(float)/scaler\n",
        "    scaledInputData = scaledData.values.tolist()\n",
        "    return scaledData, scaledInputData\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "EJBPJF-EbRP-",
        "cellView": "form",
        "outputId": "79336ad1-c84c-4246-a153-08a3da24608e"
      },
      "source": [
        "#@title **Click here to conduct pairwise tests**\n",
        "#@markdown This step computes a two-tailed Brunner-Munzel test, Mann-Whitney U-test, Welch's t-test, and Student's t-test for each taxon between each pair of sites. A Bonferroni-Dunn correction (PBD) is also computed for each returned P-value. This step uses a Shapiro-Wilk test to determine data normality (whether the data was sampled from a Gaussian distribution) and a Levene's test to determine equivariance between each sample set. Gaussian likelihood and equivariance likelihood results are used to determine which pairwise test is most appropriate.\n",
        "\n",
        "datasetName = next(iter(dataset))\n",
        "dataset_df = pd.read_csv(io.BytesIO(dataset[datasetName]), sep='\\t', header=None).set_index(0)\n",
        "dataset_head = pd.DataFrame(dataset_df.iloc[0].tolist())\n",
        "dataset_head = dataset_head.rename(columns={0:\"Group\"}).T #.set_index('Group')\n",
        "\n",
        "if scale_data==\"yes\":\n",
        "  sdata1, sdata2 = Scale(dataset_df.drop('Group'))\n",
        "  sdata1 = sdata1.T.reset_index().T.drop('index')\n",
        "  dataset_df = pd.concat([dataset_head, sdata1])\n",
        "  #dataset_df1 = dataset_head.append(sdata1)\n",
        "else:\n",
        "  dataset_df = dataset_df\n",
        "\n",
        "\n",
        "\n",
        "groupedData = dataset_df.T.groupby(\"Group\", axis=0)\n",
        "groups = set(dataset_df.iloc[0].tolist())\n",
        "taxa = list(dataset_df.T.columns)[1:]\n",
        "\n",
        "reformatted_data = []\n",
        "\n",
        "for group in groups:\n",
        "  rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "  for taxonID, dataSeries in rawDataset.iteritems():\n",
        "    dataSeries = list(dataSeries.astype(np.float))\n",
        "    x = [taxonID, group, list(dataSeries)]\n",
        "    reformatted_data.append(x)\n",
        "\n",
        "results = []\n",
        "BrunnerMunzelResults = []\n",
        "StudentResults = []\n",
        "WelchResults = []\n",
        "MannWhitneyResults = []\n",
        "KruskalResults = []\n",
        "\n",
        "combi = itertools.combinations(reformatted_data,2)\n",
        "for groupA, groupB in combi:\n",
        "  if (groupA[0]==groupB[0]) and (groupA[1]!=groupB[1]):\n",
        "    lenA, lenB = len(groupA[2]), len(groupB[2])\n",
        "    if (np.mean(groupA[2]) > 0) and (np.std(groupA[2])>0) and (np.mean(groupB[2])>0) and (np.std(groupB[2])>0) and (lenA > 1) and (lenB > 1):\n",
        "      L, P = stats.levene(groupA[2], groupB[2])\n",
        "      K1, KP1 = stats.shapiro(groupA[2])\n",
        "      K2, KP2 = stats.shapiro(groupB[2])\n",
        "      Mean1, SD1, Median1, Var1, min1, max1 = np.mean(groupA[2]), np.std(groupA[2]), np.median(groupA[2]), np.var(groupA[2]), min(groupA[2]), max(groupA[2])\n",
        "      Mean2, SD2, Median2, Var2, min2, max2 = np.mean(groupB[2]), np.std(groupB[2]), np.median(groupB[2]), np.var(groupB[2]), min(groupB[2]), max(groupB[2])\n",
        "      Brunner_Stat, Brunner_P = stats.brunnermunzel(groupA[2], groupB[2])\n",
        "      Student_Stat, Student_P = stats.ttest_ind(groupA[2], groupB[2], equal_var=True)\n",
        "      Welch_Stat, Welch_P = stats.ttest_ind(groupA[2], groupB[2], equal_var=False)\n",
        "      KW_Stat, KW_P = stats.kruskal(groupA[2], groupB[2])\n",
        "      MW_Stat, MW_P = stats.mannwhitneyu(groupA[2], groupB[2])\n",
        "      if Mean1 > Mean2:\n",
        "        MeanDifference = \"Decrease\"\n",
        "      elif Mean1 < Mean2:\n",
        "        MeanDifference = \"Increase\"\n",
        "      else:\n",
        "        MeanDifference = \"NoChange\"    \n",
        "      if Median1 > Median2:\n",
        "        MedianDifference = \"Decrease\"\n",
        "      elif Median1 < Median2:\n",
        "        MedianDifference = \"Increase\"\n",
        "      else:\n",
        "        MedianDifference = \"NoChange\"\n",
        "      if P >= pairwise_equivariance_critical_alpha:\n",
        "        equivariance = \"equivariant\"\n",
        "      else:\n",
        "        equivariance = \"non-equivariant\"\n",
        "      if KP1 >= pairwise_gaussian_critical_alpha:\n",
        "        distribution1 = \"gaussian\"\n",
        "      else:\n",
        "        distribution1 = \"non-gaussian\"\n",
        "      if KP2 >= pairwise_gaussian_critical_alpha:\n",
        "        distribution2 = \"gaussian\"\n",
        "      else:\n",
        "       distribution2 = \"non-gaussian\"\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, Brunner_Stat, Brunner_P]\n",
        "      BrunnerMunzelResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, MW_Stat, MW_P]\n",
        "      MannWhitneyResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MedianDifference, KW_Stat, KW_P]\n",
        "      KruskalResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MeanDifference, Student_Stat, Student_P]\n",
        "      StudentResults.append(ComparisonResult)\n",
        "      ComparisonResult = [groupA[0], groupA[1], groupB[1], Mean1, SD1, Median1, Var1, lenA, min1, max1, Mean2, SD2, Median2, Var2, lenB, min2, max2, MeanDifference, Welch_Stat, Welch_P]\n",
        "      WelchResults.append(ComparisonResult)\n",
        "      if (distribution1 == \"gaussian\") and (distribution2 == \"gaussian\") and (equivariance == \"equivariant\"):\n",
        "        recommendation = \"Students_t_test\"\n",
        "      elif (distribution1 == \"gaussian\") and (distribution2 == \"gaussian\") and (equivariance == \"non-equivariant\"):\n",
        "        recommendation = \"Welchs_t_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"non-equivariant\") and min(lenA,lenB)>9:\n",
        "        recommendation = \"Brunner-Munzel_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"non-equivariant\") and min(lenA,lenB)<9 and min(lenA,lenB)>4:\n",
        "        recommendation = \"Kruskal-Wallis_H_test\"\n",
        "      elif ((distribution1 == \"non-gaussian\") or (distribution2 == \"non-gaussian\")) and (equivariance == \"equivariant\") and min(lenA,lenB)>7:\n",
        "       recommendation = \"Mann-Whitney_U_test\"\n",
        "      elif min(lenA,lenB)<4 and (equivariance == \"equivariant\"):\n",
        "        recommendation = \"Size_Students_t_test\"\n",
        "      elif min(lenA,lenB)<4 and (equivariance == \"non-equivariant\"):\n",
        "        recommendation = \"Size_Welchs_t_test\"\n",
        "      else:\n",
        "        \"Check_statistics\"\n",
        "      result = [groupA[0], groupA[1], groupB[1], lenA, lenB, L, K1, K2, P, KP1, KP2, equivariance, distribution1, distribution2, recommendation]\n",
        "      results.append(result)\n",
        "\n",
        "tests_df = pd.DataFrame.from_records(results, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"SizeA\", \"SizeB\", \"Levenes_Stat\", \"KS_StatA\", \"KS_StatB\", \"Levenes_Pvalue\", \"KS_PvalueA\", \"KS_PvalueB\", \"Equivariant?\", \"GroupA_Gaussian?\", \"GroupB_Gaussian?\", \"Recommended_test\"])\n",
        "BrunnerMunzelResults_df = pd.DataFrame.from_records(BrunnerMunzelResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "StudentResults_df = pd.DataFrame.from_records(StudentResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "WelchResults_df = pd.DataFrame.from_records(WelchResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "MannWhitneyResults_df = pd.DataFrame.from_records(MannWhitneyResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "KruskalResults_df = pd.DataFrame.from_records(KruskalResults, columns=[\"Taxon\", \"GroupA\", \"GroupB\", \"MeanA\", \"StDevA\", \"MedianA\", \"VarianceA\", \"SizeA\", \"MinimumA\", \"MaximumA\", \"MeanB\", \"StDevB\", \"MedianB\", \"VarianceB\", \"SizeB\", \"MinimumB\", \"MaximumB\", \"Difference\", \"Statistic\", \"Pvalue\"])\n",
        "\n",
        "res_df = tests_df['Recommended_test'].value_counts()\n",
        "set_tests = tests_df['Recommended_test'].unique()\n",
        "if \"Kruskal-Wallis_H_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Kruskal-Wallis H test\\n***\\n\")\n",
        "elif \"Brunner-Munzel_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Brunner-Munzel test\\n***\\n\") \n",
        "elif \"Welchs_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Welchs t test\\n***\\n\") \n",
        "elif \"Students_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Students t test\\n***\\n\") \n",
        "elif \"Mann-Whitney_U_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Mann-Whitney U test\\n***\\n\")\n",
        "elif \"Size_Welchs_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Size-based Welchs t test\\n***\\n\") \n",
        "elif \"Size_Students_t_test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Size-based Students t test\\n***\\n\") \n",
        "\n",
        "if \"Size_\" in set_tests:\n",
        "  print(\"\\n***Warning: A \\\"size based\\\" t-test was invoked for one or more comparisons.\\nThis happens when the sample size is below 5 in a given group.\\nPlease check your data\")\n",
        "\n",
        "KruskalResults_df['PBD'] = multipletests(KruskalResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "BrunnerMunzelResults_df['PBD'] = multipletests(BrunnerMunzelResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "StudentResults_df['PBD'] = multipletests(StudentResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "WelchResults_df['PBD'] = multipletests(WelchResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "MannWhitneyResults_df['PBD'] = multipletests(MannWhitneyResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "\n",
        "tests_df.to_csv(\"RecommendedPairwiseComparisons.tsv\", sep='\\t', header=True, index=False)\n",
        "KruskalResults_df.to_csv(\"KruskalPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "BrunnerMunzelResults_df.to_csv(\"BrunnerMunzelPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "StudentResults_df.to_csv(\"StudentPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "WelchResults_df.to_csv(\"WelchPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "MannWhitneyResults_df.to_csv(\"MannWhitneyPairwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "recTable = pd.DataFrame(tests_df['Recommended_test'].value_counts()).rename(columns={\"Recommended_test\":\"n\"})\n",
        "recTable['%'] = round((recTable/recTable.sum()*100),3)\n",
        "print(\"\\n***\\nThe below table shows the number of tests (n) associated with each test\\nand their associated percentage of the total number of tests (%)\\n***\")\n",
        "recTable\n",
        "\n",
        "#dataset_df\n",
        "#sdata1.T.reset_index().T.drop('index')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "***\n",
            "The recommended test for all comparisons is the Brunner-Munzel test\n",
            "***\n",
            "\n",
            "\n",
            "***\n",
            "The below table shows the number of tests (n) associated with each test\n",
            "and their associated percentage of the total number of tests (%)\n",
            "***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Brunner-Munzel_test</th>\n",
              "      <td>873</td>\n",
              "      <td>68.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mann-Whitney_U_test</th>\n",
              "      <td>386</td>\n",
              "      <td>30.490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Welchs_t_test</th>\n",
              "      <td>5</td>\n",
              "      <td>0.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students_t_test</th>\n",
              "      <td>2</td>\n",
              "      <td>0.158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       n       %\n",
              "Brunner-Munzel_test  873  68.957\n",
              "Mann-Whitney_U_test  386  30.490\n",
              "Welchs_t_test          5   0.395\n",
              "Students_t_test        2   0.158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "XhhM6e4ux5PD",
        "cellView": "form",
        "outputId": "53d8efb4-c4bc-46c5-fa38-e48309c1524e"
      },
      "source": [
        "#@title **Click here to conduct listwise tests**\n",
        "#@markdown This step computes an ANOVA and a Kruskal-Wallis H-test for each taxon between each pair of sites. A Bonferroni-Dunn correction (PBD) is also computed for each returned P-value. This step uses a Shapiro-Wilk test to determine data normality (whether the data was sampled from a Gaussian distribution) and a Levene's test to determine equivariance between each sample set. Gaussian likelihood and equivariance likelihood results are used to determine which listwise test is most appropriate.\n",
        "\n",
        "\n",
        "ANOVA_results = []\n",
        "H_results = []\n",
        "listwise_results = []\n",
        "\n",
        "for taxon in taxa:\n",
        "  experimental = []\n",
        "  for group in reformatted_data:\n",
        "    if taxon == group[0]:\n",
        "      experimental.append(group[2])\n",
        "  groupings = [item for item in experimental]\n",
        "  Levenes_Stat, Levenes_P = stats.levene(*groupings)\n",
        "  KWS, KWP = stats.kruskal(*groupings)\n",
        "  ANS, ANP = stats.f_oneway(*groupings)\n",
        "  H_res = [taxon, KWS, KWP]\n",
        "  ANOVA_res = [taxon, ANS, ANP]\n",
        "  ANOVA_results.append(ANOVA_res)\n",
        "  H_results.append(H_res)\n",
        "  Gauss = []\n",
        "  for group in groupings:\n",
        "    KS, KP = stats.kstest(group, 'norm')\n",
        "    KSP = [KS, KP]\n",
        "    Gauss.append(KSP)\n",
        "  KS, KP = min(Gauss)\n",
        "  if (KP >= listwise_gaussian_critical_alpha) and (Levenes_P >= listwise_equivariance_critical_alpha):\n",
        "    recommendation = \"ANOVA\"\n",
        "  else:\n",
        "    recommendation = \"Kruskal-Wallis_H-test\"\n",
        "  lres = [taxon, Levenes_Stat, KS, Levenes_P, KP, recommendation]\n",
        "  listwise_results.append(lres)\n",
        "\n",
        "KruskalListwiseResults_df = pd.DataFrame.from_records(H_results, columns=[\"Taxon\", \"Statistic\", \"Pvalue\"])\n",
        "KruskalListwiseResults_df['PBD'] = multipletests(KruskalListwiseResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "KruskalListwiseResults_df.to_csv(\"KruskalListwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "ANOVAListwiseResults_df = pd.DataFrame.from_records(ANOVA_results, columns=[\"Taxon\", \"Statistic\", \"Pvalue\"])\n",
        "ANOVAListwiseResults_df['PBD'] = multipletests(ANOVAListwiseResults_df['Pvalue'], method='Bonferroni')[1]\n",
        "ANOVAListwiseResults_df.to_csv(\"ANOVAListwiseResults.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "tests_df = pd.DataFrame.from_records(listwise_results, columns=[\"Taxon\", \"Levene_Stat\", \"Levene_P\", \"min_KS_Stat\", \"min_KS_P\", \"Recommended_test\"])\n",
        "tests_df.to_csv(\"RecommendedListwiseComparisons.tsv\", sep='\\t', header=True, index=False)\n",
        "\n",
        "set_tests = tests_df['Recommended_test'].unique()\n",
        "if \"Kruskal-Wallis_H-test\" in set_tests:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is the Kruskal-Wallis H test\\n***\\n\")\n",
        "else:\n",
        "  print(\"\\n***\\nThe recommended test for all comparisons is ANOVA\\n***\\n\") \n",
        "\n",
        "recTable = pd.DataFrame(tests_df['Recommended_test'].value_counts()).rename(columns={\"Recommended_test\":\"n\"})\n",
        "recTable['%'] = round((recTable/recTable.sum()*100),3)\n",
        "print(\"\\n***\\nThe below table shows the number of tests (n) associated with each test\\nand their associated percentage of the total number of tests (%)\\n***\")\n",
        "recTable\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "***\n",
            "The recommended test for all comparisons is the Kruskal-Wallis H test\n",
            "***\n",
            "\n",
            "\n",
            "***\n",
            "The below table shows the number of tests (n) associated with each test\n",
            "and their associated percentage of the total number of tests (%)\n",
            "***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Kruskal-Wallis_H-test</th>\n",
              "      <td>12</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        n      %\n",
              "Kruskal-Wallis_H-test  12  100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrqY_aKMalCK",
        "cellView": "form"
      },
      "source": [
        "#@title **Plot variance distributions**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate differential variances. This step can be slow due to the volume of graphs produced (and data processed) for large and complex datasets. To speed up this process, only comparisons where the median of both datasets is greater than 0 are plotted.\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "combi = itertools.combinations(reformatted_data,2)\n",
        "with PdfPages(\"VarianceDistributions.pdf\") as pdf:\n",
        "  for groupA, groupB in combi:\n",
        "    if (groupA[0]==groupB[0]) and (groupA[1]!=groupB[1]):\n",
        "      if (np.mean(groupA[2]) > 0) and (np.std(groupA[2])>0) and (np.mean(groupB[2])>0) and (np.std(groupB[2])>0) and (np.median(groupA[2])>0) and (np.median(groupB[2])>0):\n",
        "        L, P = stats.levene(groupA[2], groupB[2])\n",
        "        groupAA = scaler.fit_transform(np.array(groupA[2]).reshape(-1,1)).tolist()\n",
        "        groupBB = scaler.fit_transform(np.array(groupB[2]).reshape(-1,1)).tolist()\n",
        "        groupAA = list(itertools.chain(*groupAA))\n",
        "        groupBB = list(itertools.chain(*groupBB))\n",
        "        z = pd.DataFrame([groupAA, groupBB]).T\n",
        "        ax = sns.displot(data=z, stat='probability', common_norm=False, kde='True', palette=['blue','red'], legend=None)\n",
        "        plt.title(groupA[0])\n",
        "        plt.xlabel('Standardised reads')\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_equivariance_critical_alpha :\n",
        "          ax2.set_ylabel(\"Equivariant (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_equivariance_critical_alpha) and (P > 0.001):\n",
        "          ax2.set_ylabel(\"Non-equivariant (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-equivariant (P = \"+format(P,'.3e')+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=groupA[1]),mpatches.Patch(facecolor='blue', label=groupB[1])]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()\n",
        "        del groupAA, groupBB\n",
        "        continue\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h91yZqPZuE8",
        "cellView": "form"
      },
      "source": [
        "#@title **Plot data standardised distributions against a Gaussian distribution**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate whether a given taxon at a given site was sampled from a Gaussian distribution.\n",
        "\n",
        "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "with PdfPages(\"GaussianDistributions.pdf\") as pdf:  \n",
        "  for group in groups:\n",
        "    rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "    for taxonID, dataSeries in rawDataset.iteritems():\n",
        "      dataSeries = list(dataSeries.astype(np.float))\n",
        "      if (np.mean(dataSeries) > 0) and (np.std(dataSeries)>0) and (np.median(dataSeries)>0):\n",
        "        K,P = stats.shapiro(dataSeries)\n",
        "        dataSeries = scaler.fit_transform(np.array(dataSeries).reshape(-1,1)).tolist()\n",
        "        dataSeries = list(itertools.chain(*dataSeries))\n",
        "        normal_data = np.random.normal(loc=0.0, scale=1.0, size=min(len(dataSeries)**2, 10000))\n",
        "        z = pd.DataFrame([normal_data, dataSeries]).T\n",
        "        ax = sns.displot(data=z, stat='probability', common_norm=False, kde='True', palette=['blue','red'], legend=None)\n",
        "        plt.title(taxonID+\" (\"+group+\")\")\n",
        "        plt.xlabel('Standardised reads (deviations from the mean)')\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_gaussian_critical_alpha:\n",
        "          ax2.set_ylabel(\"Gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_gaussian_critical_alpha) and (P > 0.001):\n",
        "         ax2.set_ylabel(\"Non-gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+format(P,'.3e')+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=taxonID),mpatches.Patch(facecolor='blue', label=\"Gaussian distribution\")]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.25), ncol=2)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDAN_m_fbi9p",
        "cellView": "form"
      },
      "source": [
        "#@title **Plot QQ-plots**\n",
        "#@markdown This step constructs comparative standardised distributions to illustrate whether a given taxon at a given site was sampled from a Gaussian distribution (presented in a linear QQ-plot format).\n",
        "\n",
        "\n",
        "with PdfPages(\"QQ_plots.pdf\") as pdf:  \n",
        "  for group in groups:\n",
        "    rawDataset = groupedData.get_group(group).set_index(\"Group\")\n",
        "    for taxonID, dataSeries in rawDataset.iteritems():\n",
        "      if (np.mean(dataSeries) > 0) and (np.std(dataSeries)>0) and (np.median(dataSeries)>0):        \n",
        "        dataSeries = np.array(dataSeries.astype(np.float))\n",
        "        K,P = stats.shapiro(dataSeries)\n",
        "        sm.qqplot(dataSeries, stats.norm, fit=True, line='45', loc=np.mean(dataSeries), scale=np.std(dataSeries))\n",
        "        ax2 = plt.twinx()\n",
        "        ax2.set_yticks([])\n",
        "        if P > pairwise_gaussian_critical_alpha:\n",
        "          ax2.set_ylabel(\"Gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        elif (P <= pairwise_gaussian_critical_alpha) and (P > 0.001):\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+str(round(P,3))+\")\")\n",
        "        else:\n",
        "          ax2.set_ylabel(\"Non-gaussian (P = \"+format(P,'.3e')+\")\")\n",
        "        plt.title(taxonID+\" (\"+group+\")\")\n",
        "        handles = [mpatches.Patch(facecolor='red', label=\"QQ-line (45 degrees)\"),mpatches.Patch(facecolor='blue', label=taxonID)]\n",
        "        plt.legend(handles=handles, loc=\"lower center\", bbox_to_anchor=(0.5, -0.35), ncol=2)\n",
        "        fig=plt.gca().get_figure()\n",
        "        fig.subplots_adjust(bottom=0.25)\n",
        "        pdf.savefig(fig, bbox_inches='tight')\n",
        "        #plt.show()\n",
        "        plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}